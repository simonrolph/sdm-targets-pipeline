---
title: "Pipeline set up - environmental and species data"
author: "Simon Rolph"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
library(sf)
library(terra)
library(rgbif)
library(dplyr)
```

## Overview

This is a non-pipelined set-up script for processing environmental data and downloading species data from GBIF.

## Configuration

Update this line to point towards the shapefile of your area of interest

```{r}
AOI_boundary_file_location = "data/raw/boundaries/SG_CairngormsNationalPark_2010/SG_CairngormsNationalPark_2010.shp"
```

Put any environmental data rasters (eg. from GEE) in `data/raw/environmental/` as `.tif` files, on the same grid size/alignment.

## Environmental data

This script prepares the environmental data (climate, land-use etc.)

This script is currently not run as part of the {targets} pipeline. An output file of this script are loaded into the pipeline as files. This output is a `.tif` file containing the environmental data for the target region and is saved in this location. `data/derived/environmental/env-layers-OSGB.tif` 

The are of interest (AOI) boundary, represented as well known text (WKT) is saved to `data/derived/environmental/AOI_WKT.txt`and used when querying GBIF.

Define extent

```{r}
#read in the park boundary
boundary <- st_read(AOI_boundary_file_location)

#this outputs the bounding box which can be used in the GEE script
boundary %>% st_bbox()

#appriximate WKT of park with a bit of buffering
park_wkt <- boundary %>%
  st_buffer(10000) %>% # buffer by 10k
  st_transform(4326) %>% #transform to wgs1984
  st_simplify(dTolerance=1000) %>% # simplify
  st_geometry() %>% #only select the geometry to that st_as_text() works properly
  st_as_text()

#write the boundary of the AOI (area of interest) as WKT which can be used for querying GBIF
writeLines(park_wkt,"data/derived/environmental/AOI_WKT.txt")

```

Load layers which have been downloaded from google earth engine and reproject to OSGB

```{r}
#combine into one spatRaster
env_layers <- rast(list.files("data/raw/environmental/",full.names = T,pattern=".tif"))

#(optional)project to OSGB
#env_layers <- project(env_layers,"EPSG:27700")

#(optionally) mask to the park boundary
#env_layers <- env_layers %>% mask(boundary %>% st_buffer(10000))

#proximity measures
env_layers_proximity <- env_layers[[c('water','grass','flooded_vegetation','crops','shrub_and_scrub','built','bare','snow_and_ice')]]
names(env_layers_proximity) <- paste0("prox_",names(env_layers_proximity))

env_layers_proximity <- env_layers_proximity %>% aggregate(fact=9)


#create a Gaussian window to use as smoothing
w <- rayimage::generate_2d_gaussian(
  sd = 4,
  dim = c(11, 11),
  rescale_unity = T
)
image(w)

#apply the smoothing
#do a coarse moving window with max
env_layers_proximity2 <-  focal(env_layers_proximity,w=w, fun=max)

#then do a nicer smooth with mean
env_layers_proximity2 <-  focal(env_layers_proximity2,w=w, fun=mean)

# resample back to original resolution
env_layers_proximity2 <- resample(env_layers_proximity2,env_layers)

#add it to the other layers
env_layers <- c(env_layers,env_layers_proximity2)

# set cells with water are set to NA on all layers because we are only modelling terrestrial species
env_layers[env_layers$water>15] <- NA

#(optionally) aggregate to make coarser for quicker model runs
env_layers <- env_layers %>% aggregate(fact=4)

env_layers

#save the raster  
writeRaster(env_layers,filename = "data/derived/environmental/env-layers-OSGB.tif",overwrite=T)

```

### Species list

The species list is stored as a text file of GBIF taxon IDs in `sp_list.txt`. You can add more species by looking up their taxon key on gbif and adding it to the list. This list is used to define the values in `tar_map()`.

```{r,eval = F}
sp_list_taxon_id <- readLines("data/raw/species/sp_list.txt")
```

### Download species data

This code chunk downloads the data from GBIF using R package `rgbif` 

```{r,eval = F}
#make data request
aoi_wkt <- readLines("data/derived/environmental/AOI_WKT.txt") # the area of interest
sp_data_request <- occ_download(pred_in("taxonKey",sp_list_taxon_id),
                                pred("gadm","GBR.3_1"),
                                pred_lt("coordinateUncertaintyInMeters",101),
                                pred_within(aoi_wkt))

#wait until the download is ready
occ_download_wait(sp_data_request[1])

# get data
d <- occ_download_get(sp_data_request[1],path = "data/raw/occurence/") %>% 
    occ_download_import()

#save the full data
saveRDS(d,"data/raw/occurence/sp_data_raw.rds")

#read it back in
#d <- readRDS("data/raw/occurence/sp_data_raw.rds")

#split the data into taxa
for (sp in sp_list_taxon_id){
  d %>% 
    dplyr::filter(taxonKey == sp) %>%
    saveRDS(paste0("data/raw/occurence/",sp,".rds"))
}

```

## Run pipeline

```{r}
targets::tar_make()
targets::tar_make_clustermq()
tar_visnetwork(T)
```


